---
title: ChatGPT Operator 遭提示注入攻击
published: true
---
# ChatGPT Operator 的提示注入漏洞及其缓解措施

OpenAI 为 ChatGPT Pro 用户打造的前沿研究预览工具 **ChatGPT Operator** 近来因一个严重漏洞引发关注。该漏洞可通过提示注入攻击，致使敏感个人数据面临泄露风险。

## ChatGPT Operator 简介

**ChatGPT Operator** 是一款功能强大的先进 AI 代理，具备网页浏览与推理能力，能帮助用户执行多种任务，如研究特定主题、预订旅行行程，甚至代表用户与各类网站进行交互。然而，近期的一些演示却揭示出它存在安全隐患 —— 可在与网页交互过程中被恶意操控，进而导致隐私数据泄露。

## 攻击原理：提示注入如何运作

根据 wunderwuzzi 的博客介绍，提示注入是一种将恶意指令嵌入 AI 模型处理的文本或网页内容中的技术。对于 ChatGPT Operator，这种攻击涉及以下步骤：

### 攻击流程

1. **通过提示注入劫持 Operator**：
    - 恶意指令托管在 GitHub Issues 等平台或嵌入到网站文本中。

2. **导航至敏感页面**：
    - 攻击者诱骗 Operator 访问包含敏感个人信息（如电子邮件或电话号码）的认证页面。

3. **通过第三方网站泄露数据**：
    - Operator 被进一步操纵，将这些信息复制并粘贴到恶意网页中，无需表单提交即可捕获数据。
    - ![这是一个示例GIF](https://plate-num.oss-cn-beijing.aliyuncs.com/1739865954895911_bb46be5e46104377b19ec5a74b9e136d%21small.gif)
### 示例演示

例如，在一次演示中，Operator 被诱骗从用户的 YC Hacker News 帐户中提取私人电子邮件地址，并将其粘贴到第三方服务器的输入字段中。这种攻击在 Booking.com 和 The Guardian 等多个网站上均能无缝执行。

## 缓解措施

OpenAI 已实施多层次的防御措施来降低此类风险：

### 1. 用户监控

- 提示用户监控 Operator 的行为，包括输入的文本和点击的按钮。但这在很大程度上依赖于用户的警惕性。

### 2. 内联确认请求

- 对于某些操作，Operator 会在聊天界面中请求用户确认后再继续执行。虽然在某些情况下有效，但在早期测试中被绕过。

### 3. 带外确认请求

- 在跨网站边界或执行复杂操作时，Operator 会显示侵入式确认对话框，解释潜在风险。然而，这些防御措施并非万无一失。

尽管如此，由于提示注入攻击具有概率性，攻击和防御都取决于特定条件是否满足，因此这类攻击仍然部分有效。

## 安全隐患与挑战

这些演示中暴露的漏洞引发了严重关切：如果被利用，攻击者可能会访问存储在认证网站上的敏感个人信息。由于 Operator 会话在服务器端运行，OpenAI 可能也会访问会话 Cookie、授权令牌和其他敏感数据。

这些攻击削弱了人们对自主 AI 代理的信任，凸显了对强大安全措施的需求。

## 解决方案建议

为解决这些挑战，OpenAI 可以考虑以下措施：

### 开源提示注入监控器

- 开源其提示注入监控器的一部分，或分享其防御机制的详细文档。这将使研究人员能够评估和改进现有的缓解策略。

### 阻止 AI 代理访问敏感页面

- 网站可以通过识别独特的 User-Agent 标头，采取阻止 AI 代理访问敏感页面的措施。

### 强化防御措施

- 继续开发针对恶意指令的强大防御措施，确保完全自主的代理能够在更安全的环境中运行。

提示注入攻击表明，在开发出针对恶意指令的强大防御措施之前，完全自主的代理可能仍难以实现。目前，警惕的监控和分层的缓解措施对于保护用户隐私和维持对 AI 技术的信任至关重要。
